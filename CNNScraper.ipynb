{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the results line by line to a csv file\n",
    "def toFile(out_file, results):\n",
    "    with open(out_file + '.csv', \"w\", encoding=\"utf-8\") as o:\n",
    "        write = csv.writer(o)\n",
    "        write.writerows(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the required information from the json object\n",
    "def extract(response):\n",
    "    results = []\n",
    "    for result in response.json()['result']:\n",
    "        results.append([result['url'], result['headline'], result['firstPublishDate'], result['body'][:350]])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(query, out_file):\n",
    "    #It's the API that CNN uses to get their data. \n",
    "    #We use this just to avoid rendering Javascript.\n",
    "    url = 'https://search.api.cnn.io/content'\n",
    "    #The first query to get the first 50 results\n",
    "    params = { 'q' : query ,'size' : 50, 'page' : 1}\n",
    "    response = requests.get(url = url, params = params)\n",
    "    #We get the total number of results, so now we know how many more pages we have to request.\n",
    "    #We round up the result after the division\n",
    "    pages = response.json()['meta']['of']/50\n",
    "    roundedUp = int(math.ceil(pages))\n",
    "    results = extract(response)\n",
    "    for page in range(2, roundedUp+1):\n",
    "        fromPage = (page - 1) * 50\n",
    "        params = { 'q' : query ,'size' : 50, 'from' :  fromPage, 'page' : page}\n",
    "        #Sleep for 0.5 second just for safety :) \n",
    "        time.sleep(0.5)\n",
    "        response = requests.get(url = url, params = params)\n",
    "        results += extract(response)\n",
    "    toFile(out_file, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_news('holiday greece', 'holiday_greece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
